import os
import re
import json
import asyncio
import logging
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
import openai

logger = logging.getLogger(__name__)

@dataclass
class ThinkingStep:
    """æ€è€ƒæ­¥éª¤"""
    content: str
    step_type: str  # reasoning, calculation, verification, correction
    confidence: float
    is_correction: bool = False
    parent_step: Optional[int] = None

@dataclass
class O1BeamNode:
    """O1æ¨ç†èŠ‚ç‚¹"""
    id: str
    content: str
    reasoning_type: str
    quality_score: float
    probability: float
    parent: Optional[str]
    children: List[str]
    variables: List[str]
    depth: int
    original_text: str  # ä¿ç•™åŸå§‹thinkingæ–‡æœ¬
    is_correction: bool = False

class O1ReasoningParser:
    """O1æ¨ç†è§£æå™¨"""
    
    def __init__(self):
        # æ¨ç†ç±»å‹å…³é”®è¯
        self.reasoning_keywords = {
            'problem_understanding': [
                'let me understand', 'let me see', 'this is a', 'the problem is',
                'i need to', 'first', 'looking at', 'this asks', 'we have'
            ],
            'calculation': [
                'calculate', 'compute', 'sum', 'multiply', 'divide', 'equals',
                'formula', 'substitute', 'simplify', 'solve'
            ],
            'verification': [
                'let me check', 'verify', 'double check', 'confirm', 'make sure',
                'does this make sense', 'checking'
            ],
            'correction': [
                'wait', 'actually', 'no', 'that\'s wrong', 'let me reconsider',
                'i made an error', 'correction', 'instead', 'rather'
            ],
            'conclusion': [
                'therefore', 'so', 'final answer', 'the answer is', 'conclusion',
                'result', 'hence'
            ]
        }
    
    def parse_thinking_content(self, thinking_text: str) -> List[ThinkingStep]:
        """è§£æthinkingå†…å®¹ä¸ºæ­¥éª¤"""
        
        # æŒ‰å¥å·ã€æ¢è¡Œç­‰åˆ†å‰²thinkingå†…å®¹
        sentences = self._split_thinking_text(thinking_text)
        
        steps = []
        for i, sentence in enumerate(sentences):
            if len(sentence.strip()) < 10:  # è·³è¿‡å¤ªçŸ­çš„ç‰‡æ®µ
                continue
            
            step_type = self._classify_step_type(sentence)
            confidence = self._calculate_confidence(sentence, step_type)
            is_correction = self._is_correction_step(sentence)
            
            step = ThinkingStep(
                content=sentence.strip(),
                step_type=step_type,
                confidence=confidence,
                is_correction=is_correction,
                parent_step=i-1 if i > 0 else None
            )
            steps.append(step)
        
        return steps
    
    def _split_thinking_text(self, text: str) -> List[str]:
        """æ™ºèƒ½åˆ†å‰²thinkingæ–‡æœ¬"""
        
        # å…ˆæŒ‰æ˜æ˜¾çš„åˆ†éš”ç¬¦åˆ†å‰²
        # å¤„ç†å¤šç§åˆ†éš”æ¨¡å¼
        patterns = [
            r'\n\n+',  # åŒæ¢è¡Œ
            r'\.\s+(?=[A-Z])',  # å¥å·åè·Ÿå¤§å†™å­—æ¯
            r'(?<=\.)\s*(?=Let me|I need|Now|Next|So|The)',  # ç‰¹å®šå¼€å¤´è¯
            r'(?<=\.)\s*(?=\d+\.)',  # ç¼–å·åˆ—è¡¨
        ]
        
        sentences = [text]
        for pattern in patterns:
            new_sentences = []
            for sentence in sentences:
                new_sentences.extend(re.split(pattern, sentence))
            sentences = new_sentences
        
        # æ¸…ç†å’Œè¿‡æ»¤
        cleaned_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence and len(sentence) > 10:
                cleaned_sentences.append(sentence)
        
        return cleaned_sentences
    
    def _classify_step_type(self, text: str) -> str:
        """åˆ†ç±»æ­¥éª¤ç±»å‹"""
        text_lower = text.lower()
        
        scores = {}
        for step_type, keywords in self.reasoning_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                scores[step_type] = score
        
        if not scores:
            return 'reasoning'
        
        return max(scores, key=scores.get)
    
    def _calculate_confidence(self, text: str, step_type: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°"""
        base_score = 0.5
        
        # åŸºäºé•¿åº¦
        length_bonus = min(0.3, len(text) / 200)
        
        # åŸºäºæ•°å­¦å†…å®¹
        math_keywords = ['=', '+', '-', '*', '/', 'formula', 'equation', 'calculate']
        math_score = sum(0.05 for keyword in math_keywords if keyword in text.lower())
        
        # åŸºäºç¡®å®šæ€§è¯­è¨€
        certainty_keywords = ['clearly', 'obviously', 'definitely', 'certainly']
        uncertainty_keywords = ['maybe', 'perhaps', 'might', 'possibly', 'i think']
        
        certainty_score = sum(0.1 for keyword in certainty_keywords if keyword in text.lower())
        uncertainty_penalty = sum(0.1 for keyword in uncertainty_keywords if keyword in text.lower())
        
        # åŸºäºæ­¥éª¤ç±»å‹
        type_bonus = {
            'calculation': 0.2,
            'verification': 0.15,
            'conclusion': 0.25,
            'correction': -0.1,
            'problem_understanding': 0.1
        }.get(step_type, 0)
        
        final_score = base_score + length_bonus + math_score + certainty_score - uncertainty_penalty + type_bonus
        
        return max(0.1, min(1.0, final_score))
    
    def _is_correction_step(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºçº æ­£æ­¥éª¤"""
        correction_indicators = [
            'wait', 'actually', 'no', 'wrong', 'mistake', 'error', 
            'let me reconsider', 'that\'s not right', 'correction'
        ]
        
        text_lower = text.lower()
        return any(indicator in text_lower for indicator in correction_indicators)
    
    def build_beam_tree(self, thinking_steps: List[ThinkingStep], final_answer: str) -> Dict[str, O1BeamNode]:
        """æ„å»ºbeam searchæ ‘"""
        
        beam_tree = {}
        
        # æ ¹èŠ‚ç‚¹
        beam_tree["root"] = O1BeamNode(
            id="root",
            content="[O1] Starting to analyze the problem",
            reasoning_type="start",
            quality_score=1.0,
            probability=1.0,
            parent=None,
            children=[],
            variables=["problem_analysis"],
            depth=0,
            original_text="",
            is_correction=False
        )
        
        # å¤„ç†æ€è€ƒæ­¥éª¤
        previous_node_id = "root"
        main_path_nodes = ["root"]
        correction_branches = []
        
        for i, step in enumerate(thinking_steps):
            node_id = f"step_{i}"
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºçº æ­£åˆ†æ”¯
            if step.is_correction and i > 0:
                # åˆ›å»ºçº æ­£åˆ†æ”¯
                correction_branch_id = f"correction_{i}"
                parent_id = main_path_nodes[-2] if len(main_path_nodes) > 1 else "root"
                
                correction_node = O1BeamNode(
                    id=correction_branch_id,
                    content=f"[O1] {step.content[:80]}..." if len(step.content) > 80 else f"[O1] {step.content}",
                    reasoning_type=step.step_type,
                    quality_score=max(0.3, step.confidence * 0.8),  # çº æ­£æ­¥éª¤è´¨é‡ç•¥ä½
                    probability=step.confidence * 0.7,
                    parent=parent_id,
                    children=[],
                    variables=[f"correction_{i}"],
                    depth=len([n for n in main_path_nodes if not n.startswith("correction")]),
                    original_text=step.content,
                    is_correction=True
                )
                
                beam_tree[correction_branch_id] = correction_node
                
                # æ›´æ–°çˆ¶èŠ‚ç‚¹çš„children
                if parent_id in beam_tree:
                    beam_tree[parent_id].children.append(correction_branch_id)
                
                correction_branches.append(correction_branch_id)
                
            else:
                # ä¸»è·¯å¾„èŠ‚ç‚¹
                main_node = O1BeamNode(
                    id=node_id,
                    content=f"[O1] {step.content[:80]}..." if len(step.content) > 80 else f"[O1] {step.content}",
                    reasoning_type=step.step_type,
                    quality_score=step.confidence,
                    probability=step.confidence * 0.9,
                    parent=previous_node_id,
                    children=[],
                    variables=[f"step_{i}_analysis"],
                    depth=len(main_path_nodes),
                    original_text=step.content,
                    is_correction=False
                )
                
                beam_tree[node_id] = main_node
                
                # æ›´æ–°çˆ¶èŠ‚ç‚¹çš„children
                if previous_node_id in beam_tree:
                    beam_tree[previous_node_id].children.append(node_id)
                
                main_path_nodes.append(node_id)
                previous_node_id = node_id
        
        # æ·»åŠ æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹
        final_node_id = "final_answer"
        final_node = O1BeamNode(
            id=final_node_id,
            content=f"[O1] Final Answer: {final_answer}",
            reasoning_type="conclusion",
            quality_score=0.95,
            probability=0.9,
            parent=previous_node_id,
            children=[],
            variables=["final_answer", "conclusion"],
            depth=len(main_path_nodes),
            original_text=final_answer,
            is_correction=False
        )
        
        beam_tree[final_node_id] = final_node
        
        # æ›´æ–°å€’æ•°ç¬¬äºŒä¸ªèŠ‚ç‚¹çš„children
        if previous_node_id in beam_tree:
            beam_tree[previous_node_id].children.append(final_node_id)
        
        return beam_tree
    
    def extract_paths(self, beam_tree: Dict[str, O1BeamNode]) -> List[Dict[str, Any]]:
        """æå–æ¨ç†è·¯å¾„"""
        paths = []
        
        # ä¸»è·¯å¾„ï¼ˆæœ€é«˜è´¨é‡è·¯å¾„ï¼‰
        main_path_nodes = []
        current_node = "root"
        
        while current_node:
            main_path_nodes.append(current_node)
            node = beam_tree[current_node]
            
            # é€‰æ‹©è´¨é‡æœ€é«˜çš„å­èŠ‚ç‚¹
            if node.children:
                best_child = max(node.children, 
                               key=lambda child_id: beam_tree[child_id].quality_score)
                current_node = best_child
            else:
                current_node = None
        
        # è®¡ç®—ä¸»è·¯å¾„è´¨é‡
        main_path_scores = [beam_tree[node_id].quality_score for node_id in main_path_nodes]
        main_path_avg = sum(main_path_scores) / len(main_path_scores)
        
        main_path = {
            "id": "main_path",
            "nodes": main_path_nodes,
            "quality": "excellent" if main_path_avg >= 0.8 else "good" if main_path_avg >= 0.6 else "fair",
            "score": main_path_avg,
            "is_correct": main_path_avg > 0.7,
            "final_answer": "Extracted from O1",
            "path_type": "main_reasoning"
        }
        
        paths.append(main_path)
        
        # æ·»åŠ åŒ…å«çº æ­£çš„æ›¿ä»£è·¯å¾„
        correction_nodes = [node_id for node_id, node in beam_tree.items() if node.is_correction]
        if correction_nodes:
            # æ„å»ºåŒ…å«çº æ­£çš„è·¯å¾„
            alt_path_nodes = ["root"]
            for node_id in correction_nodes[:3]:  # æœ€å¤šåŒ…å«3ä¸ªçº æ­£
                alt_path_nodes.append(node_id)
            
            if alt_path_nodes:
                alt_path_scores = [beam_tree[node_id].quality_score for node_id in alt_path_nodes]
                alt_path_avg = sum(alt_path_scores) / len(alt_path_scores)
                
                alt_path = {
                    "id": "correction_path",
                    "nodes": alt_path_nodes,
                    "quality": "fair",
                    "score": alt_path_avg,
                    "is_correct": False,
                    "final_answer": "Alternative approach",
                    "path_type": "correction_branch"
                }
                
                paths.append(alt_path)
        
        return paths

class O1ReasoningClient:
    """O1æ¨ç†å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            logger.warning("No OpenAI API key found")
            self.client = None
        else:
            self.client = openai.AsyncOpenAI(api_key=self.api_key)
            logger.info("âœ… O1 client initialized")
        
        self.parser = O1ReasoningParser()
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨"""
        return self.client is not None
    
    async def generate_reasoning(self, question: str, **kwargs) -> Dict[str, Any]:
        """ä½¿ç”¨O1ç”Ÿæˆæ¨ç†"""
        
        if not self.client:
            return {
                "success": False,
                "error": "O1 client not available - missing API key",
                "model": "O1"
            }
        
        try:
            logger.info(f"ğŸ§  Generating O1 reasoning for question: {question[:50]}...")
            
            # è°ƒç”¨O1 API
            response = await self.client.chat.completions.create(
                model="o1-preview",  # æˆ– "o1-mini"
                messages=[
                    {
                        "role": "user",
                        "content": f"Please solve this problem step by step, showing your detailed reasoning:\n\n{question}"
                    }
                ],
                max_completion_tokens=kwargs.get("max_tokens", 3000)
            )
            
            # è·å–å®Œæ•´å›ç­”
            full_response = response.choices[0].message.content
            logger.info(f"âœ… O1 response received ({len(full_response)} chars)")
            
            # æå–thinkingå’Œæœ€ç»ˆç­”æ¡ˆ
            thinking_content, final_answer = self._extract_thinking_and_answer(full_response)
            
            if not thinking_content:
                logger.warning("No thinking content found in O1 response")
                thinking_content = full_response  # ä½¿ç”¨æ•´ä¸ªå›ç­”ä½œä¸ºthinking
                final_answer = "See reasoning above"
            
            # è§£æthinkingè¿‡ç¨‹
            thinking_steps = self.parser.parse_thinking_content(thinking_content)
            logger.info(f"ğŸ“Š Parsed {len(thinking_steps)} thinking steps")
            
            # æ„å»ºbeam tree
            beam_tree = self.parser.build_beam_tree(thinking_steps, final_answer)
            
            # æå–è·¯å¾„
            paths = self.parser.extract_paths(beam_tree)
            
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "success": True,
                "model": "O1",
                "problem": {
                    "question": question,
                    "model": "O1",
                    "options": self._extract_options_from_question(question)
                },
                "beam_tree": {k: asdict(v) for k, v in beam_tree.items()},
                "paths": paths,
                "model_info": {
                    "name": "OpenAI O1",
                    "type": "real_api",
                    "model_id": "o1-preview",
                    "thinking_steps": len(thinking_steps)
                },
                "raw_response": full_response,
                "thinking_content": thinking_content
            }
            
            logger.info(f"ğŸ‰ O1 reasoning generated: {len(beam_tree)} nodes, {len(paths)} paths")
            return result
            
        except Exception as e:
            logger.error(f"âŒ O1 API error: {str(e)}")
            return {
                "success": False,
                "error": f"O1 API error: {str(e)}",
                "model": "O1"
            }
    
    def _extract_thinking_and_answer(self, response: str) -> Tuple[str, str]:
        """æå–thinkingå†…å®¹å’Œæœ€ç»ˆç­”æ¡ˆ"""
        
        # O1çš„thinkingé€šå¸¸åœ¨<thinking>æ ‡ç­¾å†…ï¼Œä½†æœ‰æ—¶æ ¼å¼ä¸åŒ
        thinking_patterns = [
            r'<thinking>(.*?)</thinking>',
            r'<think>(.*?)</think>',
            r'Let me think through this step by step\.(.*?)(?=\n\n|\nSo |Therefore |The answer is)',
            r'I need to.*?(?=\n\n|\nSo |\nTherefore |\nThe answer is)'
        ]
        
        thinking_content = ""
        for pattern in thinking_patterns:
            match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
            if match:
                thinking_content = match.group(1).strip()
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°thinkingæ ‡ç­¾ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        if not thinking_content:
            # æŸ¥æ‰¾æ˜æ˜¾çš„æ¨ç†éƒ¨åˆ†
            lines = response.split('\n')
            reasoning_lines = []
            
            for line in lines:
                if any(keyword in line.lower() for keyword in [
                    'let me', 'i need to', 'first', 'then', 'so', 'therefore',
                    'step', 'calculate', 'solve'
                ]):
                    reasoning_lines.append(line)
            
            if reasoning_lines:
                thinking_content = '\n'.join(reasoning_lines)
        
        # æå–æœ€ç»ˆç­”æ¡ˆ
        answer_patterns = [
            r'(?:The answer is|Final answer|Answer:|Therefore,?)\s*([A-E]\).*?)(?:\n|$)',
            r'([A-E]\).*?)(?:\n|$)',
            r'(?:Therefore|So|Hence),?\s*(.*?)(?:\n|$)'
        ]
        
        final_answer = "Answer not clearly identified"
        for pattern in answer_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                final_answer = match.group(1).strip()
                break
        
        return thinking_content, final_answer
    
    def _extract_options_from_question(self, question: str) -> List[str]:
        """ä»é—®é¢˜ä¸­æå–é€‰é¡¹"""
        option_pattern = r'([A-E]\)[^A-E]*?)(?=[A-E]\)|$)'
        matches = re.findall(option_pattern, question, re.DOTALL)
        
        options = []
        for match in matches:
            option = match.strip()
            if option:
                options.append(option)
        
        return options if options else ["A) Option A", "B) Option B", "C) Option C", "D) Option D"]

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
async def test_o1_reasoning():
    """æµ‹è¯•O1æ¨ç†"""
    
    # éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡
    client = O1ReasoningClient()
    
    if not client.is_available():
        print("âŒ O1 client not available - please set OPENAI_API_KEY")
        return
    
    test_question = """Let S be the sum of the first nine terms of the sequence x+a, xÂ²+2a, xÂ³+3a, ... Then S equals:
A) (50a+x+xâ¸)/(x+1)
B) 50a-(x+xÂ¹â°)/(x-1)
C) (xâ¹-1)/(x+1)+45a
D) (xÂ¹â°-x)/(x-1)+45a"""
    
    print("ğŸ§ª Testing O1 reasoning...")
    result = await client.generate_reasoning(test_question)
    
    if result["success"]:
        print("âœ… O1 reasoning successful!")
        print(f"Generated {len(result['beam_tree'])} nodes")
        print(f"Found {len(result['paths'])} reasoning paths")
        print(f"Thinking steps: {result['model_info']['thinking_steps']}")
        
        # ä¿å­˜ç»“æœç”¨äºæŸ¥çœ‹
        with open("o1_reasoning_test.json", "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print("ğŸ“ Results saved to o1_reasoning_test.json")
        
    else:
        print(f"âŒ O1 reasoning failed: {result['error']}")

if __name__ == "__main__":
    asyncio.run(test_o1_reasoning())