import torch
import json
import time
import logging
import numpy as np
import os
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import re

try:
    from local_deepseek_engine import LocalDeepSeekR1Engine
    LOCAL_DEEPSEEK_AVAILABLE = True
except ImportError:
    LOCAL_DEEPSEEK_AVAILABLE = False
    print("âš ï¸ Local DeepSeek engine not available")

try:
    from deepseek_reasoning_client import DeepSeekReasoningClient
    DEEPSEEK_CLIENT_AVAILABLE = True
except ImportError:
    DEEPSEEK_CLIENT_AVAILABLE = False
    print("âš ï¸ DeepSeek client not available")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class FrontendBeamNode:
    """Node format matching frontend requirements"""
    id: str
    content: str
    reasoning_type: str
    quality_score: float
    probability: float
    parent: Optional[str]
    children: List[str]
    variables: List[str]
    depth: int

@dataclass
class FrontendPath:
    """Path format matching frontend requirements"""
    id: str
    nodes: List[str]
    quality: str
    score: float
    is_correct: bool
    final_answer: str

@dataclass
class FrontendBeamResult:
    """Complete result format for frontend"""
    problem: Dict[str, Any]
    beam_tree: Dict[str, Dict[str, Any]]
    paths: List[Dict[str, Any]]

class LocalDeepSeekReasoningParser:
    """è§£ææœ¬åœ° DeepSeek R1 æ¨ç†ç»“æœ"""
    
    def __init__(self):
        # æ¨ç†ç±»å‹å…³é”®è¯
        self.reasoning_keywords = {
            'problem_understanding': [
                'understand', 'analyze', 'this problem', 'we need to',
                'first', 'looking at', 'the question', 'given'
            ],
            'calculation': [
                'calculate', 'compute', 'sum', 'multiply', 'divide', 'equals',
                'formula', 'substitute', 'simplify', 'solve', 'step'
            ],
            'verification': [
                'check', 'verify', 'confirm', 'make sure',
                'does this make sense', 'validation', 'double check'
            ],
            'correction': [
                'wait', 'actually', 'no', 'wrong', 'reconsider',
                'error', 'correction', 'instead', 'mistake'
            ],
            'conclusion': [
                'therefore', 'so', 'final answer', 'answer is', 'conclusion',
                'result', 'hence', 'summary'
            ]
        }
    
    def parse_local_deepseek_result(self, deepseek_result: Dict[str, Any]) -> Tuple[Dict[str, FrontendBeamNode], List[FrontendPath]]:
        """è§£ææœ¬åœ° DeepSeek ç»“æœä¸º beam search æ ¼å¼"""
        
        if not deepseek_result.get("success", False):
            # è¿”å›é”™è¯¯èŠ‚ç‚¹
            error_tree = {
                "root": FrontendBeamNode(
                    id="root",
                    content=f"Local DeepSeek Error: {deepseek_result.get('error', 'Unknown error')}",
                    reasoning_type="error",
                    quality_score=0.0,
                    probability=0.0,
                    parent=None,
                    children=[],
                    variables=["error"],
                    depth=0
                )
            }
            return error_tree, []
        
        thinking_content = deepseek_result.get("thinking_content", "")
        final_answer = deepseek_result.get("final_answer", "")
        
        # åˆ†å‰²æ€è€ƒè¿‡ç¨‹ä¸ºæ­¥éª¤
        thinking_steps = self._split_thinking_text(thinking_content)
        
        # æ„å»º beam tree
        beam_tree = self._build_beam_tree_from_steps(thinking_steps, final_answer)
        
        # æå–è·¯å¾„
        paths = self._extract_paths_from_tree(beam_tree)
        
        return beam_tree, paths
    
    def _split_thinking_text(self, text: str) -> List[str]:
        """æ™ºèƒ½åˆ†å‰²æ€è€ƒæ–‡æœ¬ä¸ºæ­¥éª¤"""
        if not text:
            return ["No thinking process available"]
        
        # æŒ‰ç…§æ®µè½ã€å¥å­ç­‰åˆ†å‰²
        patterns = [
            r'\n\n+',  # æ®µè½åˆ†å‰²
            r'\.\s+(?=[A-Z])',  # å¥å­åˆ†å‰²ï¼ˆå¤§å†™å­—æ¯å¼€å¤´ï¼‰
            r'(?<=\.)\s*(?=Step|Now|Next|So|The|First|Second|Third)',  # æ­¥éª¤æ ‡è¯†
            r'(?<=:)\s*(?=[A-Z])',  # å†’å·ååˆ†å‰²
        ]
        
        sentences = [text]
        for pattern in patterns:
            new_sentences = []
            for sentence in sentences:
                new_sentences.extend(re.split(pattern, sentence))
            sentences = new_sentences
        
        # æ¸…ç†å’Œè¿‡æ»¤
        cleaned_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence and len(sentence) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                sentence = re.sub(r'\s+', ' ', sentence)  # æ ‡å‡†åŒ–ç©ºç™½
                cleaned_sentences.append(sentence)
        
        return cleaned_sentences if cleaned_sentences else ["Reasoning step processed"]
    
    def _build_beam_tree_from_steps(self, steps: List[str], final_answer: str) -> Dict[str, FrontendBeamNode]:
        """ä»æ­¥éª¤æ„å»º beam tree"""
        tree = {}
        
        # æ ¹èŠ‚ç‚¹
        tree["root"] = FrontendBeamNode(
            id="root",
            content="[Local DeepSeek R1] Starting mathematical problem analysis",
            reasoning_type="start",
            quality_score=1.0,
            probability=1.0,
            parent=None,
            children=[],
            variables=["local_deepseek_start"],
            depth=0
        )
        
        previous_node_id = "root"
        
        # å¤„ç†æ¯ä¸ªæ€è€ƒæ­¥éª¤
        for i, step in enumerate(steps):
            node_id = f"step_{i}"
            
            # åˆ†ç±»æ­¥éª¤ç±»å‹
            step_type = self._classify_step_type(step)
            
            # è®¡ç®—è´¨é‡åˆ†æ•°
            quality_score = self._calculate_step_quality(step, step_type)
            
            # åˆ›å»ºèŠ‚ç‚¹
            node = FrontendBeamNode(
                id=node_id,
                content=f"[Local DeepSeek] {step[:100]}..." if len(step) > 100 else f"[Local DeepSeek] {step}",
                reasoning_type=step_type,
                quality_score=quality_score,
                probability=quality_score * 0.9,
                parent=previous_node_id,
                children=[],
                variables=[f"local_step_{i}", step_type],
                depth=i + 1
            )
            
            tree[node_id] = node
            
            # æ›´æ–°çˆ¶èŠ‚ç‚¹çš„ children
            if previous_node_id in tree:
                tree[previous_node_id].children.append(node_id)
            
            previous_node_id = node_id
        
        # æ·»åŠ æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹
        final_node_id = "final_answer"
        final_node = FrontendBeamNode(
            id=final_node_id,
            content=f"[Local DeepSeek] Final Answer: {final_answer}",
            reasoning_type="conclusion",
            quality_score=0.95,
            probability=0.92,
            parent=previous_node_id,
            children=[],
            variables=["local_final_answer", "conclusion"],
            depth=len(steps) + 1
        )
        
        tree[final_node_id] = final_node
        
        if previous_node_id in tree:
            tree[previous_node_id].children.append(final_node_id)
        
        return tree
    
    def _classify_step_type(self, text: str) -> str:
        """åˆ†ç±»æ­¥éª¤ç±»å‹"""
        text_lower = text.lower()
        
        scores = {}
        for step_type, keywords in self.reasoning_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                scores[step_type] = score
        
        if not scores:
            return 'reasoning'
        
        return max(scores, key=scores.get)
    
    def _calculate_step_quality(self, text: str, step_type: str) -> float:
        """è®¡ç®—æ­¥éª¤è´¨é‡åˆ†æ•°"""
        base_score = 0.6
        
        # é•¿åº¦å¥–åŠ±
        length_bonus = min(0.2, len(text) / 200)
        
        # æ•°å­¦å…³é”®è¯å¥–åŠ±
        math_keywords = ['=', '+', '-', '*', '/', 'equation', 'formula', 'calculate']
        math_score = sum(0.03 for keyword in math_keywords if keyword in text.lower())
        
        # ç¡®å®šæ€§å…³é”®è¯
        certainty_keywords = ['clearly', 'obviously', 'definitely', 'therefore']
        uncertainty_keywords = ['maybe', 'perhaps', 'might', 'possibly']
        
        certainty_score = sum(0.05 for keyword in certainty_keywords if keyword in text.lower())
        uncertainty_penalty = sum(0.05 for keyword in uncertainty_keywords if keyword in text.lower())
        
        # æ­¥éª¤ç±»å‹å¥–åŠ±
        type_bonus = {
            'calculation': 0.15,
            'verification': 0.1,
            'conclusion': 0.2,
            'correction': -0.05,
            'problem_understanding': 0.08
        }.get(step_type, 0.05)
        
        final_score = (base_score + length_bonus + math_score + certainty_score + 
                      type_bonus - uncertainty_penalty)
        
        return max(0.2, min(0.98, final_score))
    
    def _extract_paths_from_tree(self, beam_tree: Dict[str, FrontendBeamNode]) -> List[FrontendPath]:
        """ä» tree æå–è·¯å¾„"""
        paths = []
        
        # æ‰¾åˆ°ä¸»è·¯å¾„ï¼ˆä» root åˆ°å¶å­èŠ‚ç‚¹ï¼‰
        def find_main_path(node_id: str, current_path: List[str]):
            node = beam_tree[node_id]
            current_path = current_path + [node_id]
            
            if not node.children:  # å¶å­èŠ‚ç‚¹
                # è®¡ç®—è·¯å¾„è´¨é‡
                path_scores = [beam_tree[nid].quality_score for nid in current_path]
                avg_score = float(np.mean(path_scores))
                
                # ç¡®å®šè´¨é‡æ ‡ç­¾
                if avg_score >= 0.85:
                    quality = "excellent"
                elif avg_score >= 0.7:
                    quality = "good"
                elif avg_score >= 0.5:
                    quality = "fair"
                else:
                    quality = "poor"
                
                # æå–æœ€ç»ˆç­”æ¡ˆ
                final_answer = self._extract_answer_from_content(node.content)
                
                # åˆ›å»ºè·¯å¾„
                path = FrontendPath(
                    id=f"local_path_{len(paths)}",
                    nodes=current_path,
                    quality=quality,
                    score=avg_score,
                    is_correct=avg_score > 0.75,
                    final_answer=final_answer
                )
                paths.append(path)
            else:
                # ç»§ç»­éå†å­èŠ‚ç‚¹
                for child_id in node.children:
                    if child_id in beam_tree:
                        find_main_path(child_id, current_path)
        
        find_main_path("root", [])
        
        # æŒ‰åˆ†æ•°æ’åº
        paths.sort(key=lambda p: p.score, reverse=True)
        return paths[:3]  # è¿”å›å‰3æ¡è·¯å¾„
    
    def _extract_answer_from_content(self, content: str) -> str:
        """ä»å†…å®¹ä¸­æå–ç­”æ¡ˆ"""
        # å°è¯•æå–é€‰æ‹©é¢˜ç­”æ¡ˆ
        answer_match = re.search(r'\b([A-E])\)', content)
        if answer_match:
            return answer_match.group(1)
        
        # å°è¯•æå–æ•°å­—ç­”æ¡ˆ
        number_match = re.search(r'answer.*?(\d+(?:\.\d+)?)', content, re.IGNORECASE)
        if number_match:
            return number_match.group(1)
        
        # å°è¯•æå–ç­‰å¼
        equals_match = re.search(r'x\s*=\s*(\d+(?:\.\d+)?)', content)
        if equals_match:
            return f"x = {equals_match.group(1)}"
        
        return "A"  # é»˜è®¤è¿”å›

class ProblemClassifier:
    """Classify mathematical problem types"""
    
    def __init__(self):
        self.patterns = {
            "sequence": [
                "sequence", "series", "sum", "term", "arithmetic", "geometric",
                "first.*terms", "nth term", "Î£", "summation", "consecutive"
            ],
            "geometry": [
                "triangle", "circle", "angle", "area", "perimeter", "volume",
                "rectangle", "square", "polygon", "diameter", "radius"
            ],
            "algebra": [
                "equation", "solve", "variable", "polynomial", "factor",
                "quadratic", "linear", "system", "inequality", "roots"
            ],
            "probability": [
                "probability", "chance", "random", "dice", "coin", "card",
                "outcome", "event", "sample space", "conditional"
            ],
            "calculus": [
                "derivative", "integral", "limit", "continuous", "differential",
                "rate of change", "optimization", "maximum", "minimum"
            ]
        }
    
    def classify_problem(self, question: str) -> str:
        """Classify problem type based on keywords"""
        question_lower = question.lower()
        
        scores = {}
        for problem_type, keywords in self.patterns.items():
            score = sum(1 for keyword in keywords if keyword in question_lower)
            if score > 0:
                scores[problem_type] = score
        
        if not scores:
            return "general"
        
        return max(scores, key=scores.get)

class EnhancedLocalDeepSeekBeamGenerator:
    """å¢å¼ºçš„æœ¬åœ° DeepSeek Beam Search ç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 model_path: str = "deepseek-ai/deepseek-math-7b-instruct",
                 cache_dir: str = "/app/models",
                 gpu_id: int = 1,
                 use_local_engine: bool = True,
                 fallback_to_api: bool = True):
        """
        Args:
            model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„
            cache_dir: ç¼“å­˜ç›®å½•
            gpu_id: GPU ID
            use_local_engine: æ˜¯å¦ä½¿ç”¨æœ¬åœ°å¼•æ“
            fallback_to_api: æ˜¯å¦å›é€€åˆ° API
        """
        self.device = self._setup_device()
        self.classifier = ProblemClassifier()
        self.parser = LocalDeepSeekReasoningParser()
        self.use_local_engine = use_local_engine
        self.fallback_to_api = fallback_to_api
        
        # åˆå§‹åŒ–æœ¬åœ° DeepSeek å¼•æ“
        self.local_engine = None
        if use_local_engine and LOCAL_DEEPSEEK_AVAILABLE:
            try:
                self.local_engine = LocalDeepSeekR1Engine(
                    model_path=model_path,
                    cache_dir=cache_dir,
                    gpu_id=gpu_id
                )
                logger.info("âœ… Local DeepSeek engine initialized")
            except Exception as e:
                logger.error(f"âŒ Failed to initialize local DeepSeek engine: {e}")
                if not fallback_to_api:
                    raise
                self.local_engine = None
        
        # åˆå§‹åŒ– API å®¢æˆ·ç«¯ä½œä¸ºå¤‡ç”¨
        self.deepseek_client = None
        if fallback_to_api and DEEPSEEK_CLIENT_AVAILABLE:
            try:
                self.deepseek_client = DeepSeekReasoningClient()
                if self.deepseek_client.is_available():
                    logger.info("âœ… DeepSeek API client available as fallback")
            except Exception as e:
                logger.error(f"âŒ Failed to initialize DeepSeek client: {e}")
                self.deepseek_client = None
        
        logger.info(f"Enhanced Local DeepSeek generator initialized")
        logger.info(f"  Local engine: {self.local_engine is not None}")
        logger.info(f"  API fallback: {self.deepseek_client is not None and self.deepseek_client.is_available()}")
    
    def _setup_device(self):
        """Setup compute device"""
        if torch.cuda.is_available():
            device = torch.device('cuda:1')  # ä½¿ç”¨ GPU 1
            logger.info(f"Using GPU: {torch.cuda.get_device_name(1)}")
            return device
        else:
            return torch.device('cpu')
    
    async def generate_reasoning_beam_search(
        self, 
        question: str, 
        beam_width: int = 3,
        max_depth: int = 5,
        force_api: bool = False
    ) -> FrontendBeamResult:
        """ç”Ÿæˆ beam search æ¨ç†"""
        
        start_time = time.time()
        
        # ç¡®å®šä½¿ç”¨å“ªç§æ–¹æ³•
        use_local = (
            self.use_local_engine and 
            self.local_engine and 
            not force_api
        )
        
        if use_local:
            logger.info("ğŸ¤– Using local DeepSeek R1 engine")
            try:
                result = await self._generate_with_local_engine(question)
                generation_time = time.time() - start_time
                logger.info(f"âœ… Local DeepSeek completed in {generation_time:.2f}s")
                return result
            except Exception as e:
                logger.error(f"âŒ Local DeepSeek failed: {e}")
                if self.fallback_to_api and self.deepseek_client and self.deepseek_client.is_available():
                    logger.info("ğŸ”„ Falling back to DeepSeek API")
                    return await self._generate_with_api(question)
                else:
                    raise
        else:
            if self.deepseek_client and self.deepseek_client.is_available():
                logger.info("ğŸŒ Using DeepSeek API")
                result = await self._generate_with_api(question)
                generation_time = time.time() - start_time
                logger.info(f"âœ… DeepSeek API completed in {generation_time:.2f}s")
                return result
            else:
                raise Exception("No DeepSeek engine available (local or API)")
    
    async def _generate_with_local_engine(self, question: str) -> FrontendBeamResult:
        """ä½¿ç”¨æœ¬åœ°å¼•æ“ç”Ÿæˆæ¨ç†"""
        
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if not self.local_engine.is_loaded:
            logger.info("ğŸ“¥ Loading local DeepSeek model...")
            if not self.local_engine.load_model():
                raise Exception("Failed to load local DeepSeek model")
        
        # ç”Ÿæˆæ¨ç†
        deepseek_result = self.local_engine.generate_reasoning(
            question, 
            max_new_tokens=3000,
            temperature=0.1
        )
        
        if not deepseek_result.get("success", False):
            raise Exception(f"Local DeepSeek generation failed: {deepseek_result.get('error', 'Unknown error')}")
        
        # è§£æç»“æœä¸º beam search æ ¼å¼
        beam_tree, paths = self.parser.parse_local_deepseek_result(deepseek_result)
        
        # åˆ†ç±»é—®é¢˜ç±»å‹
        problem_type = self.classifier.classify_problem(question)
        
        # æ„å»ºè¿”å›ç»“æœ
        result = FrontendBeamResult(
            problem={
                "question": question,
                "options": self._extract_options(question),
                "problem_type": problem_type,
                "reasoning_source": "local_deepseek_r1"
            },
            beam_tree={k: asdict(v) for k, v in beam_tree.items()},
            paths=[asdict(p) for p in paths]
        )
        
        return result
    
    async def _generate_with_api(self, question: str) -> FrontendBeamResult:
        """ä½¿ç”¨ API ç”Ÿæˆæ¨ç†"""
        
        # è°ƒç”¨ DeepSeek API
        deepseek_result = await self.deepseek_client.generate_reasoning(
            question, 
            max_tokens=3000,
            temperature=0.1
        )
        
        if not deepseek_result.get("success", False):
            raise Exception(f"DeepSeek API error: {deepseek_result.get('error', 'Unknown error')}")
        
        # è½¬æ¢ä¸ºå‰ç«¯æ ¼å¼
        beam_tree = {}
        for node_id, node_data in deepseek_result["beam_tree"].items():
            beam_tree[node_id] = {
                "id": node_data["id"],
                "content": node_data["content"],
                "reasoning_type": node_data["reasoning_type"],
                "quality_score": float(node_data["quality_score"]),
                "probability": float(node_data["probability"]),
                "parent": node_data["parent"],
                "children": node_data["children"],
                "variables": node_data["variables"],
                "depth": int(node_data["depth"])
            }
        
        # è½¬æ¢è·¯å¾„
        paths = []
        for path_data in deepseek_result["paths"]:
            paths.append({
                "id": path_data["id"],
                "nodes": path_data["nodes"],
                "quality": path_data["quality"],
                "score": float(path_data["score"]),
                "is_correct": bool(path_data["is_correct"]),
                "final_answer": path_data["final_answer"]
            })
        
        # æå–é—®é¢˜ä¿¡æ¯
        problem_type = self.classifier.classify_problem(question)
        
        result = FrontendBeamResult(
            problem={
                "question": question,
                "options": self._extract_options(question),
                "problem_type": problem_type,
                "reasoning_source": "deepseek_api"
            },
            beam_tree=beam_tree,
            paths=paths
        )
        
        return result
    
    def _extract_options(self, question: str) -> List[str]:
        """ä»é—®é¢˜ä¸­æå–é€‰é¡¹"""
        options = []
        
        patterns = [
            r'([A-E]\)\s*[^A-E\n]*?)(?=[A-E]\)|$)',
            r'([A-E][\.\)]\s*[^A-E\n]*?)(?=[A-E][\.\)]|$)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, question, re.DOTALL)
            if matches:
                for match in matches:
                    option = match.strip()
                    if option and len(option) > 2:
                        option = re.sub(r'\s+', ' ', option)
                        options.append(option)
                break
        
        if not options:
            lines = question.split('\n')
            for line in lines:
                line = line.strip()
                if re.match(r'^[A-E][\.\)]\s*.+', line):
                    options.append(line)
        
        if not options:
            options = ["A) Option A", "B) Option B", "C) Option C", "D) Option D"]
        
        return options[:5]
    
    def is_available(self) -> bool:
        """æ£€æŸ¥ç”Ÿæˆå™¨æ˜¯å¦å¯ç”¨"""
        return (
            (self.local_engine is not None) or 
            (self.deepseek_client is not None and self.deepseek_client.is_available())
        )
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–ç”Ÿæˆå™¨çŠ¶æ€"""
        local_loaded = False
        if self.local_engine:
            local_loaded = self.local_engine.is_loaded
        
        api_available = False
        if self.deepseek_client:
            api_available = self.deepseek_client.is_available()
        
        status = {
            "local_engine_available": self.local_engine is not None,
            "local_engine_loaded": local_loaded,
            "api_client_available": api_available,
            "current_mode": "local" if local_loaded else "api" if api_available else "unavailable",
            "fallback_enabled": self.fallback_to_api
        }
        
        return status

# å‘åå…¼å®¹æ€§åŒ…è£…å™¨
def UnifiedBeamSearchGenerator(*args, **kwargs):
    """å‘åå…¼å®¹æ€§åŒ…è£…å™¨"""
    return EnhancedLocalDeepSeekBeamGenerator(*args, **kwargs)

# æ–°çš„ç»Ÿä¸€ç”Ÿæˆå™¨ï¼ŒåŒæ—¶æ”¯æŒæœ¬åœ°å’Œ API
class EnhancedUnifiedBeamSearchGenerator(EnhancedLocalDeepSeekBeamGenerator):
    """ç»Ÿä¸€çš„å¢å¼º Beam Search ç”Ÿæˆå™¨ï¼Œæ”¯æŒæœ¬åœ° DeepSeek å’Œ API"""
    pass

async def main():
    """æµ‹è¯•å¢å¼ºçš„æœ¬åœ° DeepSeek ç”Ÿæˆå™¨"""
    
    print("ğŸ§ª Testing Enhanced Local DeepSeek Beam Search Generator")
    print("=" * 60)
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "Solve: 2x + 5 = 13",
        "Find the area of a triangle with sides 3, 4, and 5.",
        "What is 15% of 200?",
        "Find the sum of the first 10 natural numbers."
    ]
    
    try:
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        generator = EnhancedLocalDeepSeekBeamGenerator(
            model_path="deepseek-ai/deepseek-math-7b-instruct",
            cache_dir="/app/models",
            gpu_id=1,
            use_local_engine=True,
            fallback_to_api=True
        )
        
        # æ£€æŸ¥çŠ¶æ€
        status = generator.get_status()
        print(f"ğŸ“Š Generator Status:")
        for key, value in status.items():
            print(f"   {key}: {value}")
        
        if not generator.is_available():
            print("âŒ Generator not available")
            return
        
        # æµ‹è¯•æ¯ä¸ªé—®é¢˜
        for i, question in enumerate(test_questions):
            print(f"\nğŸ“ Question {i+1}: {question}")
            print("-" * 40)
            
            try:
                start_time = time.time()
                result = await generator.generate_reasoning_beam_search(
                    question, 
                    beam_width=3,
                    max_depth=5
                )
                generation_time = time.time() - start_time
                
                print(f"âœ… Generated in {generation_time:.2f}s")
                print(f"   Problem type: {result.problem.get('problem_type', 'unknown')}")
                print(f"   Reasoning source: {result.problem.get('reasoning_source', 'unknown')}")
                print(f"   Tree nodes: {len(result.beam_tree)}")
                print(f"   Solution paths: {len(result.paths)}")
                
                # æ˜¾ç¤ºæœ€ä½³è·¯å¾„
                if result.paths:
                    best_path = result.paths[0]
                    print(f"   ğŸ† Best path: {best_path['quality']} quality (score: {best_path['score']:.2f})")
                    print(f"       Answer: {best_path['final_answer']}")
                    print(f"       Steps: {len(best_path['nodes'])} reasoning steps")
                
                # ä¿å­˜ç»“æœ
                filename = f"local_deepseek_result_{i+1}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    result_dict = asdict(result)
                    json.dump(result_dict, f, indent=2, ensure_ascii=False)
                print(f"   ğŸ“ Result saved: {filename}")
                
            except Exception as e:
                print(f"   âŒ Error: {str(e)}")
                import traceback
                traceback.print_exc()
    
    except Exception as e:
        print(f"âŒ Failed to initialize generator: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("ğŸ‰ Local DeepSeek testing completed!")

if __name__ == "__main__":
    asyncio.run(main())