import os
import re
import json
import asyncio
import logging
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
import openai

# å¯¼å…¥åŸæœ‰çš„ç±»
from o1_reasoning_client import O1ReasoningClient, ThinkingStep, O1BeamNode
# å¯¼å…¥å¢å¼ºç‰ˆè§£æå™¨
from enhanced_reasoning_parser import EnhancedO1ReasoningParser

logger = logging.getLogger(__name__)

class EnhancedO1ReasoningClient(O1ReasoningClient):
    """å¢å¼ºç‰ˆO1æ¨ç†å®¢æˆ·ç«¯ - ç»§æ‰¿åŸæœ‰åŠŸèƒ½ï¼Œæ·»åŠ å¢å¼ºç‰¹æ€§"""
    
    def __init__(self, api_key: Optional[str] = None, use_enhanced_parsing: bool = True):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(api_key)
        
        # é€‰æ‹©ä½¿ç”¨å¢å¼ºç‰ˆè¿˜æ˜¯åŸç‰ˆè§£æå™¨
        if use_enhanced_parsing:
            self.parser = EnhancedO1ReasoningParser()
            logger.info("âœ… Using enhanced O1 reasoning parser")
        else:
            # ä¿æŒåŸæœ‰çš„è§£æå™¨
            logger.info("â„¹ï¸ Using original O1 reasoning parser")
        
        self.enhanced_mode = use_enhanced_parsing
    
    async def generate_reasoning(self, question: str, **kwargs) -> Dict[str, Any]:
        """å¢å¼ºç‰ˆæ¨ç†ç”Ÿæˆ - ä¿æŒåŸæœ‰æ¥å£ï¼Œå†…éƒ¨ä½¿ç”¨å¢å¼ºåŠŸèƒ½"""
        
        if not self.client:
            return {
                "success": False,
                "error": "O1 client not available - missing API key",
                "model": "O1"
            }
        
        try:
            logger.info(f"ğŸ§  Generating {'enhanced ' if self.enhanced_mode else ''}O1 reasoning for question: {question[:50]}...")
            
            # ä½¿ç”¨å¢å¼ºçš„promptæ¥è·å¾—æ›´é€‚åˆbeam searchçš„æ€è€ƒè¿‡ç¨‹
            enhanced_prompt = self._create_enhanced_prompt(question) if self.enhanced_mode else question
            
            # è°ƒç”¨O1 API
            response = await self.client.chat.completions.create(
                model="o1-preview",
                messages=[
                    {
                        "role": "user", 
                        "content": enhanced_prompt
                    }
                ],
                max_completion_tokens=kwargs.get("max_tokens", 3000)
            )
            
            # è·å–å®Œæ•´å›ç­”
            full_response = response.choices[0].message.content
            logger.info(f"âœ… O1 response received ({len(full_response)} chars)")
            
            # æå–thinkingå’Œæœ€ç»ˆç­”æ¡ˆ
            thinking_content, final_answer = self._extract_thinking_and_answer(full_response)
            
            if not thinking_content:
                logger.warning("No thinking content found in O1 response")
                thinking_content = full_response
                final_answer = "See reasoning above"
            
            # ä½¿ç”¨å¢å¼ºç‰ˆè§£æå™¨è§£æthinkingè¿‡ç¨‹
            thinking_steps = self.parser.parse_thinking_content(thinking_content)
            logger.info(f"ğŸ“Š Parsed {len(thinking_steps)} thinking steps (enhanced: {self.enhanced_mode})")
            
            # æ„å»ºå¢å¼ºç‰ˆbeam tree
            beam_tree = self.parser.build_beam_tree(thinking_steps, final_answer)
            
            # æå–å¢å¼ºç‰ˆè·¯å¾„
            paths = self.parser.extract_paths(beam_tree)
            
            # æ·»åŠ å¢å¼ºåŠŸèƒ½çš„ç»Ÿè®¡ä¿¡æ¯
            enhancement_stats = self._calculate_enhancement_stats(beam_tree, paths)
            
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "success": True,
                "model": "O1",
                "problem": {
                    "question": question,
                    "model": "O1",
                    "options": self._extract_options_from_question(question)
                },
                "beam_tree": {k: asdict(v) for k, v in beam_tree.items()},
                "paths": paths,
                "model_info": {
                    "name": "OpenAI O1",
                    "type": "real_api",
                    "model_id": "o1-preview",
                    "thinking_steps": len(thinking_steps),
                    "enhanced_parsing": self.enhanced_mode,
                    "enhancement_stats": enhancement_stats
                },
                "raw_response": full_response,
                "thinking_content": thinking_content
            }
            
            enhancement_msg = f" with {enhancement_stats['total_branches']} branches" if self.enhanced_mode else ""
            logger.info(f"ğŸ‰ O1 reasoning generated: {len(beam_tree)} nodes, {len(paths)} paths{enhancement_msg}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ O1 API error: {str(e)}")
            return {
                "success": False,
                "error": f"O1 API error: {str(e)}",
                "model": "O1"
            }
    
    def _create_enhanced_prompt(self, question: str) -> str:
        """åˆ›å»ºå¢å¼ºç‰ˆpromptï¼Œå¼•å¯¼O1ç”Ÿæˆæ›´é€‚åˆbeam searchçš„æ€è€ƒè¿‡ç¨‹"""
        
        enhanced_prompt = f"""Please solve this problem using a structured reasoning approach that explores multiple perspectives:

{question}

When working through this problem:
1. First, clearly understand what's being asked
2. Consider 2-3 different approaches or methods that could work
3. For your chosen approach, work step-by-step and show your reasoning
4. At key decision points, briefly mention alternative choices you could have made
5. Double-check your calculations and reasoning
6. If you notice any potential errors or uncertainties, address them explicitly
7. Provide a clear final answer

Please show your complete thinking process, including any moments where you reconsider your approach or verify your work."""

        return enhanced_prompt
    
    def _calculate_enhancement_stats(self, beam_tree: Dict[str, O1BeamNode], paths: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—å¢å¼ºåŠŸèƒ½çš„ç»Ÿè®¡ä¿¡æ¯"""
        
        if not self.enhanced_mode:
            return {"enhanced_parsing": False}
        
        # ç»Ÿè®¡ä¸åŒç±»å‹çš„èŠ‚ç‚¹
        node_types = {}
        branch_nodes = 0
        verification_nodes = 0
        
        for node_id, node in beam_tree.items():
            node_type = node.reasoning_type
            node_types[node_type] = node_types.get(node_type, 0) + 1
            
            if node_id.startswith('branch_'):
                branch_nodes += 1
            
            if 'verification' in node_type or 'check' in node_type:
                verification_nodes += 1
        
        # ç»Ÿè®¡è·¯å¾„ç±»å‹
        path_types = {}
        for path in paths:
            path_type = path.get('path_type', 'unknown')
            path_types[path_type] = path_types.get(path_type, 0) + 1
        
        # è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°
        all_scores = [node.quality_score for node in beam_tree.values()]
        avg_quality = sum(all_scores) / len(all_scores) if all_scores else 0
        
        return {
            "enhanced_parsing": True,
            "total_nodes": len(beam_tree),
            "total_branches": branch_nodes,
            "verification_nodes": verification_nodes,
            "node_type_distribution": node_types,
            "path_type_distribution": path_types,
            "average_quality_score": round(avg_quality, 3),
            "reasoning_depth": max(node.depth for node in beam_tree.values()) if beam_tree else 0
        }

# ä¾¿æ·çš„å·¥å‚å‡½æ•°
def create_enhanced_o1_client(api_key: Optional[str] = None, enhanced: bool = True) -> EnhancedO1ReasoningClient:
    """åˆ›å»ºå¢å¼ºç‰ˆO1å®¢æˆ·ç«¯çš„ä¾¿æ·å‡½æ•°"""
    return EnhancedO1ReasoningClient(api_key=api_key, use_enhanced_parsing=enhanced)

# å‘åå…¼å®¹çš„ç±»åˆ«å
EnhancedO1Client = EnhancedO1ReasoningClient

# ä½¿ç”¨ç¤ºä¾‹
async def test_enhanced_o1():
    """æµ‹è¯•å¢å¼ºç‰ˆO1æ¨ç†"""
    
    # åˆ›å»ºå¢å¼ºç‰ˆå®¢æˆ·ç«¯
    enhanced_client = create_enhanced_o1_client(enhanced=True)
    
    # åˆ›å»ºåŸç‰ˆå®¢æˆ·ç«¯ç”¨äºå¯¹æ¯”
    original_client = create_enhanced_o1_client(enhanced=False)
    
    if not enhanced_client.is_available():
        print("âŒ O1 client not available - please set OPENAI_API_KEY")
        return
    
    test_question = """A triangle has sides of length 3, 4, and 5. 
    A) What is the area of this triangle?
    B) Is this a right triangle?
    C) What is the perimeter?"""
    
    print("ğŸ§ª Testing enhanced vs original O1 reasoning...")
    
    # æµ‹è¯•å¢å¼ºç‰ˆ
    print("\nğŸš€ Enhanced version:")
    enhanced_result = await enhanced_client.generate_reasoning(test_question)
    
    if enhanced_result["success"]:
        stats = enhanced_result["model_info"]["enhancement_stats"]
        print(f"âœ… Enhanced: {stats['total_nodes']} nodes, {stats['total_branches']} branches")
        print(f"   Path types: {list(stats['path_type_distribution'].keys())}")
        print(f"   Avg quality: {stats['average_quality_score']}")
    
    # æµ‹è¯•åŸç‰ˆ
    print("\nğŸ“ Original version:")
    original_result = await original_client.generate_reasoning(test_question)
    
    if original_result["success"]:
        print(f"âœ… Original: {len(original_result['beam_tree'])} nodes, {len(original_result['paths'])} paths")
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    comparison = {
        "enhanced": enhanced_result if enhanced_result["success"] else None,
        "original": original_result if original_result["success"] else None,
        "test_question": test_question
    }
    
    with open("enhanced_vs_original_comparison.json", "w", encoding="utf-8") as f:
        json.dump(comparison, f, indent=2, ensure_ascii=False)
    
    print("ğŸ“ Comparison saved to enhanced_vs_original_comparison.json")

if __name__ == "__main__":
    asyncio.run(test_enhanced_o1())